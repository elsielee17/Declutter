barplot_gender
cols = c("red", "blue", "green", "black")
barplot_gender <- ggplot(data)+
aes(x=gender, fill=factor(judgement))+
#scale_fill_manual(values=c("#999999", "#E69F00", "#56B4E9", "#56B4E0")+
scale_fill_manual(values = cols)+
geom_bar(stat="count")+
ggtitle("People are more likely to be judged NTA than any other judgement")+
#facet_wrap(~effectiveness)+
theme_minimal()
barplot_gender
cols = c("#07a5ad", "#59b5ba", "#bd5970", "#bf0b35")
barplot_gender <- ggplot(data)+
aes(x=gender, fill=factor(judgement))+
#scale_fill_manual(values=c("#999999", "#E69F00", "#56B4E9", "#56B4E0")+
scale_fill_manual(values = cols)+
geom_bar(stat="count")+
ggtitle("People are more likely to be judged NTA than any other judgement")+
#facet_wrap(~effectiveness)+
theme_minimal()
barplot_gender
barplot_gender_fill <- ggplot(data)+
aes(x=gender, fill=factor(judgement))+
geom_bar(stat="count", position="fill")+
scale_fill_manual(values = cols)+
ggtitle("Men are more likely to be judged the asshole than women")+
#facet_wrap(~effectiveness)+
theme_minimal()
barplot_gender_fill
data$judgement <- factor(data$judgement, levels = c("NAH", "NTA", "YTA", "ESH"))
barplot_sentiment <- ggplot(data)+
aes(x=judgement, y=sentiment, colors = cols)+
geom_bar(stat="summary")+
ggtitle("")+
#facet_wrap(~effectiveness)+
theme_minimal()
barplot_sentiment
data$judgement <- factor(data$judgement, levels = c("NAH", "NTA", "YTA", "ESH"))
barplot_sentiment <- ggplot(data)+
aes(x=judgement, y=sentiment, fill = cols)+
geom_bar(stat="summary")+
ggtitle("")+
#facet_wrap(~effectiveness)+
theme_minimal()
barplot_sentiment
data$judgement <- factor(data$judgement, levels = c("NAH", "NTA", "YTA", "ESH"))
barplot_sentiment <- ggplot(data)+
aes(x=judgement, y=sentiment)+
scale_fill_manual(values = cols)+
geom_bar(stat="summary")+
ggtitle("")+
#facet_wrap(~effectiveness)+
theme_minimal()
barplot_sentiment
data$judgement <- factor(data$judgement, levels = c("NAH", "NTA", "YTA", "ESH"))
barplot_sentiment <- ggplot(data)+
aes(x=judgement, y=sentiment, fill = cols)+
scale_fill_manual(values = cols)+
geom_bar(stat="summary")+
ggtitle("")+
#facet_wrap(~effectiveness)+
theme_minimal()
barplot_sentiment
data$judgement <- factor(data$judgement, levels = c("NAH", "NTA", "YTA", "ESH"))
barplot_sentiment <- ggplot(data)+
aes(x=judgement, y=sentiment)+
# scale_fill_manual(values = cols)+
geom_bar(stat="summary", fill = cols)+
ggtitle("")+
#facet_wrap(~effectiveness)+
theme_minimal()
barplot_sentiment
library(psycho)
library(ggplot2)
options(scipen=99)
data$gender <- factor(data$gender)
library(psycho)
library(ggplot2)
options(scipen=99)
data <- read.csv(file="AITA_topics_RS_2017.csv", stringsAsFactors = FALSE)
data <- subset(data, gender != "")
colnames(data)
summary(data$title)
for (i in 1:nrow(data)) {
# First attention check
if (data$judgement[i]=="NTA" || data$judgement[i]=="NAH") {
data$judge_binary[i] = 0
}
else if (data$judgement[i]=="YTA" || data$judgement[i]=="ESH") {
data$judge_binary[i] = 1
}
else {
data$judge_binary[i] = NA
}
}
jtbl <- table(data$gender)
jtbl
tbl <- table(data$gender, data$judgement)
tbl
# Women
round(tbl[1,]/jtbl[1], 2)
# Men
round(tbl[2,]/jtbl[2], 2)
# Neutral
round(tbl[3,]/jtbl[3], 2)
chisqtest <- chisq.test(tbl)
chisqtest
data$judgement <- factor(data$judgement, levels = c("NAH", "NTA", "YTA", "ESH"))
data$gender <- factor(data$gender)
model <- lm(judge_binary ~ gender + length + sentiment+ X0 + X1 + X3 +
X4 + X5 + X6 + X7 + X8 + X9 + X10 + X11 + X12 + X13 + X14 +
X15 + X16 + X17 + X18 + X19,
data=data, family="binomial")
summary(model)
analyze(model)
data$X0c <- scale(data$X0, center = TRUE, scale = FALSE)
data$X1c <- scale(data$X1, center = TRUE, scale = FALSE)
data$X2c <- scale(data$X2, center = TRUE, scale = FALSE)
data$X3c <- scale(data$X3, center = TRUE, scale = FALSE)
data$X4c <- scale(data$X4, center = TRUE, scale = FALSE)
data$X5c <- scale(data$X5, center = TRUE, scale = FALSE)
data$X6c <- scale(data$X6, center = TRUE, scale = FALSE)
data$X7c <- scale(data$X7, center = TRUE, scale = FALSE)
data$X8c <- scale(data$X8, center = TRUE, scale = FALSE)
data$X9c <- scale(data$X9, center = TRUE, scale = FALSE)
data$X10c <- scale(data$X10, center = TRUE, scale = FALSE)
data$X11c <- scale(data$X11, center = TRUE, scale = FALSE)
data$X12c <- scale(data$X12, center = TRUE, scale = FALSE)
data$X13c <- scale(data$X13, center = TRUE, scale = FALSE)
data$X14c <- scale(data$X14, center = TRUE, scale = FALSE)
data$X15c <- scale(data$X15, center = TRUE, scale = FALSE)
data$X16c <- scale(data$X16, center = TRUE, scale = FALSE)
data$X17c <- scale(data$X17, center = TRUE, scale = FALSE)
data$X18c <- scale(data$X18, center = TRUE, scale = FALSE)
data$X19c <- scale(data$X19, center = TRUE, scale = FALSE)
data$gender <- factor(data$gender)
model <- lm(judge_binary ~ gender + length + sentiment + X0c + X1c + X3c +
X4c + X5c + X6c + X7c + X8c + X9c + X10c + X11c + X12c + X13c + X14c +
X15c + X16c + X17c + X18c + X19c +
X0c*gender ,
data=data, family="binomial")
summary(model)
analyze(model)
data$gender <- factor(data$gender)
model <- lm(judge_binary ~ gender + length + sentiment + X0c + X1c + X3c +
X4c + X5c + X6c + X7c + X8c + X9c + X10c + X11c + X12c + X13c + X14c +
X15c + X16c + X17c + X18c + X19c +
X0c*gender + X1c*gender + X3c*gender +
,
data$gender <- factor(data$gender)
model <- lm(judge_binary ~ gender + length + sentiment + X0c + X1c + X3c +
X4c + X5c + X6c + X7c + X8c + X9c + X10c + X11c + X12c + X13c + X14c +
X15c + X16c + X17c + X18c + X19c +
X0c*gender + X1c*gender + X3c*gender
,
data=data, family="binomial")
summary(model)
analyze(model)
data$gender <- factor(data$gender)
model <- lm(judge_binary ~ gender + length + sentiment + X0c + X1c + X3c +
X4c + X5c + X6c + X7c + X8c + X9c + X10c + X11c + X12c + X13c + X14c +
X15c + X16c + X17c + X18c + X19c +
X0c*gender + X1c*gender + X3c*gender +
X4c*gender + X5c*gender + X6c*gender + X7c*gender + X8c*gender +
X9c*gender + X10c*gender + X11c*gender + X12c*gender + X13c*gender + X14c*gender +
X15c*gender + X16c*gender + X17c*gender + X18c*gender + X19c*gender
,
data=data, family="binomial")
summary(model)
analyze(model)
library(psych)
library(reshape)
library(ggplot2)
#library(ez)
library(plotly)
library(cowplot)
library(tidyr)
# takes in file created from ConfirmationBias_Guns_clean.rmd -> csv
CBdata <- read.csv(file="ConfirmationBias_Guns_clean.csv")
levels(CBdata$operationalRelevant) <- c("Strongly agree", "Agree", "Somewhat agree", "Neither agree nor disagree", "Somewhat disagree", "Disagree", "Strongly disagree")
table(CBdata$visualization, CBdata$effectiveness, CBdata$experiment)
randomization_experiment_plot <- ggplot(CBdata)+
aes(x=visualization, color=factor(experiment), fill=factor(experiment))+
geom_bar(stat="count", position = "dodge")+
ggtitle("Qualtrics Randomization + MTurk Qualification")+
theme_minimal()
randomization_experiment_plot
#take out the people who we are not analyzing
CBdata <- CBdata %>%
filter(rejected == "")
randomization_experiment_plot <- ggplot(CBdata)+
aes(x=symbolic, color=factor(experiment), fill=factor(experiment))+
geom_bar(stat="count")+
ggtitle("How far off were the MTurk Qualifications by the symbolic questions?")+
#facet_wrap(~effectiveness)+
theme_minimal()
randomization_experiment_plot
randomization_experiment_plot <- ggplot(CBdata)+
aes(x=operational, color=factor(experiment), fill=factor(experiment))+
geom_bar(stat="count")+
ggtitle("How far off were the MTurk Qualifications by the operational questions?")+
#facet_wrap(~effectiveness)+
theme_minimal()
randomization_experiment_plot
randomization_experiment_plot <- ggplot(CBdata)+
aes(x=operationalRelevant, color=factor(experiment), fill=factor(experiment))+
geom_bar(stat="count")+
ggtitle("How far off were the MTurk Qualifications by the specific relevant operational question?")+
#facet_wrap(~effectiveness)+
theme_minimal()
randomization_experiment_plot
table(CBdata$visualization, CBdata$congruency)
randomization_congruency_plot <- ggplot(CBdata)+
aes(x=visualization, color=factor(congruency), fill=factor(congruency))+
geom_bar(stat="count", position = "dodge")+
ggtitle("Qualtrics Conditions Ran + Congruency")+
theme_minimal()
randomization_congruency_plot
randomization_congruency_plot <- ggplot(CBdata)+
aes(x=visualization, color=factor(congruency), fill=factor(congruency))+
geom_bar(stat="count", position = "dodge")+
ggtitle("Qualtrics Randomization + Congruency")+
facet_wrap(~effectiveness)+
theme_minimal()
randomization_congruency_plot
accuracy_congruency_plot <- ggplot(CBdata)+
aes(x=congruency, color=factor(accuracy), fill=factor(accuracy))+
geom_bar(stat="count")+
ggtitle("Accuracy by Congruency")+
facet_wrap(~visualization)+
theme_minimal()
accuracy_congruency_plot
accuracy_congruency_fill_plot <- ggplot(CBdata)+
aes(x=congruency, color=factor(accuracy), fill=factor(accuracy))+
geom_bar(stat="count", position="fill")+
ggtitle("Accuracy by Congruency, with bars as percentages")+
facet_wrap(~visualization)+
theme_minimal()
accuracy_congruency_fill_plot
View(CBdata)
accuracy_congruency_weight_plot <- ggplot(CBdata)+
aes(x=congruency_weight, color=factor(accuracy), fill=factor(accuracy))+
geom_bar(stat="count")+
ggtitle("Accuracy by Congruency Weight")+
facet_wrap(~visualization)+
facet_wrap(~party)
theme_minimal()
accuracy_congruency_weight_plot
accuracy_congruency_weight_plot <- ggplot(CBdata)+
aes(x=congruency_weight, color=factor(accuracy), fill=factor(accuracy))+
geom_bar(stat="count")+
ggtitle("Accuracy by Congruency Weight")+
facet_grid(visualization~experiment)+
theme_minimal()
accuracy_congruency_weight_plot
accuracy_congruency_weight_plot <- ggplot(CBdata)+
aes(x=congruency_weight, color=factor(accuracy), fill=factor(accuracy))+
geom_bar(stat="count", position="fill")+
ggtitle("Accuracy by Congruency Weight")+
facet_grid(visualization~experiment)+
theme_minimal()
accuracy_congruency_weight_plot
library(psych)
library(reshape)
library(ggplot2)
#library(ez)
library(plotly)
library(cowplot)
library(tidyr)
# takes in file created from ConfirmationBias_Guns_clean.rmd -> csv
CBdata <- read.csv(file="ConfirmationBias_Guns_clean.csv")
levels(CBdata$operationalRelevant) <- c("Strongly agree", "Agree", "Somewhat agree", "Neither agree nor disagree", "Somewhat disagree", "Disagree", "Strongly disagree")
table(CBdata$visualization, CBdata$effectiveness, CBdata$experiment)
randomization_experiment_plot <- ggplot(CBdata)+
aes(x=visualization, color=factor(experiment), fill=factor(experiment))+
geom_bar(stat="count", position = "dodge")+
ggtitle("Qualtrics Randomization + MTurk Qualification")+
theme_minimal()
randomization_experiment_plot
#take out the people who we are not analyzing
CBdata <- CBdata %>%
filter(rejected == "")
randomization_experiment_plot <- ggplot(CBdata)+
aes(x=symbolic, color=factor(experiment), fill=factor(experiment))+
geom_bar(stat="count")+
ggtitle("How far off were the MTurk Qualifications by the symbolic questions?")+
#facet_wrap(~effectiveness)+
theme_minimal()
randomization_experiment_plot
randomization_experiment_plot <- ggplot(CBdata)+
aes(x=operational, color=factor(experiment), fill=factor(experiment))+
geom_bar(stat="count")+
ggtitle("How far off were the MTurk Qualifications by the operational questions?")+
#facet_wrap(~effectiveness)+
theme_minimal()
randomization_experiment_plot
randomization_experiment_plot <- ggplot(CBdata)+
aes(x=operationalRelevant, color=factor(experiment), fill=factor(experiment))+
geom_bar(stat="count")+
ggtitle("How far off were the MTurk Qualifications by the specific relevant operational question?")+
#facet_wrap(~effectiveness)+
theme_minimal()
randomization_experiment_plot
table(CBdata$visualization, CBdata$congruency)
randomization_congruency_plot <- ggplot(CBdata)+
aes(x=visualization, color=factor(congruency), fill=factor(congruency))+
geom_bar(stat="count", position = "dodge")+
ggtitle("Qualtrics Conditions Ran + Congruency")+
theme_minimal()
randomization_congruency_plot
randomization_congruency_plot <- ggplot(CBdata)+
aes(x=visualization, color=factor(congruency), fill=factor(congruency))+
geom_bar(stat="count", position = "dodge")+
ggtitle("Qualtrics Randomization + Congruency")+
facet_wrap(~effectiveness)+
theme_minimal()
randomization_congruency_plot
accuracy_congruency_plot <- ggplot(CBdata)+
aes(x=congruency, color=factor(accuracy), fill=factor(accuracy))+
geom_bar(stat="count")+
ggtitle("Accuracy by Congruency")+
facet_wrap(~visualization)+
theme_minimal()
accuracy_congruency_plot
accuracy_congruency_fill_plot <- ggplot(CBdata)+
aes(x=congruency, color=factor(accuracy), fill=factor(accuracy))+
geom_bar(stat="count", position="fill")+
ggtitle("Accuracy by Congruency, with bars as percentages")+
facet_wrap(~visualization)+
theme_minimal()
accuracy_congruency_fill_plot
CBdata$congruency_weight <- factor(CBdata$congruency_weight, levels = c("congruent_strong", "congruent_middle", "congruent_weak", "incongruent_weak", "incongruent_middle", "incongruent_strong"))
levels(CBdata$congruency_weight)[levels(CBdata$congruency_weight)=="congruent_strong"] <- "CS"
levels(CBdata$congruency_weight)[levels(CBdata$congruency_weight)=="congruent_middle"] <- "CM"
levels(CBdata$congruency_weight)[levels(CBdata$congruency_weight)=="congruent_weak"] <- "CW"
levels(CBdata$congruency_weight)[levels(CBdata$congruency_weight)=="incongruent_strong"] <- "IS"
levels(CBdata$congruency_weight)[levels(CBdata$congruency_weight)=="incongruent_middle"] <- "IM"
levels(CBdata$congruency_weight)[levels(CBdata$congruency_weight)=="incongruent_weak"] <- "IW"
accuracy_congruency_weight_plot <- ggplot(CBdata)+
aes(x=congruency_weight, color=factor(accuracy), fill=factor(accuracy))+
geom_bar(stat="count")+
ggtitle("Accuracy by Congruency Weight")+
facet_wrap(~visualization)+
theme_minimal()
accuracy_congruency_weight_plot
accuracy_congruency_weight_plot <- ggplot(CBdata)+
aes(x=congruency_weight, color=factor(accuracy), fill=factor(accuracy))+
geom_bar(stat="count", position="fill")+
ggtitle("Accuracy by Congruency Weight")+
facet_grid(visualization~party)+
theme_minimal()
accuracy_congruency_weight_plot
accuracy_congruency_weight_plot <- ggplot(CBdata)+
aes(x=congruency_weight, color=factor(accuracy), fill=factor(accuracy))+
geom_bar(stat="count")+
ggtitle("Accuracy by Congruency Weight")+
facet_grid(visualization~party)+
theme_minimal()
accuracy_congruency_weight_plot
#  Author: Caitlyn McColeman & Elsie Lee
#  Date Created: March 19 2019
#  Last Edit: March 29 2019
#
#  Visual Thinking Lab, Northwestern University
#  Originally Created For: Perception Model & Declutter
#
#  Reviewed: []
#  Verified: []
#
#  INPUT: Multiple .csvs - one from each coder for redrawn graphs, conclusions, and ratings.
#
#  OUTPUT:
#
#  Additional Comments:
#
#  Additional Scripts Used: dplyr, irr, tidyr
require('dplyr')
require('irr')
library(tidyr)
#Adding KA's data
KA_data_wide <- read.csv('IRR_declutter_conclusions_KA.csv')
KA_data_long <- gather(KA_data_wide, key = "subject", value= "coding", s1:s34)
KA_data_long$coder = "KA"
# Adding EA's data
EA_data_wide <- read.csv('IRR_declutter_conclusions_EA.csv')
EA_data_long <- gather(EA_data_wide, key = "subject", value= "coding", s1:s34)
EA_data_long$coder = "EA"
vKA_data_wide <- read.csv('IRR_declutter_conclusions_KA.csv')
require('dplyr')
require('irr')
library(tidyr)
KA_data_wide <- read.csv('IRR_declutter_conclusions_KA.csv')
setwd("/Volumes/GoogleDrive/My Drive/Declutter Study/Experiment 1 - W18 S18 W19: Stimuli, Data, Analysis/Qualitative Coding/IRR Analysis")
#Adding KA's data
KA_data_wide <- read.csv('IRR_declutter_conclusions_KA.csv')
KA_data_long <- gather(KA_data_wide, key = "subject", value= "coding", s1:s34)
KA_data_long$coder = "KA"
# Adding EA's data
EA_data_wide <- read.csv('IRR_declutter_conclusions_EA.csv')
EA_data_long <- gather(EA_data_wide, key = "subject", value= "coding", s1:s34)
EA_data_long$coder = "EA"
View(KA_data_wide)
View(KA_data_long)
KA_data_wide_r <- subset(KA_data_wide, Relevant ==1)
View(KA_data_wide_r)
#########################################################################################
## SUBJECT MATTER AND CONCLUSIONS
#Adding KA's data
KA_data_wide <- read.csv('IRR_declutter_conclusions_KA.csv')
# because analysis is at the relevancy level
KA_data_wide <- subset(KA_data_wide, Relevant == 1)
KA_data_long <- gather(KA_data_wide, key = "subject", value= "coding", s1:s34)
KA_data_long$coder = "KA"
# Adding EA's data
EA_data_wide <- read.csv('IRR_declutter_conclusions_EA.csv')
EA_data_wide <- subset(EA_data_wide, Relevant == 1)
EA_data_long <- gather(EA_data_wide, key = "subject", value= "coding", s1:s34)
EA_data_long$coder = "EA"
#Now to combine both of these
conclusions_data_long = rbind(KA_data_long, EA_data_long)
#identify coder names
coderNames = unique(conclusions_data_long$coder)
# overall agreemeent with Cohen's Kappa
# 6 is hard coded as the column with the coding
results = kappa2(cbind(KA_data_long[6], EA_data_long[6]))
results
# agreement by graph example
for (i in unique(conclusions_data_long$Graph)) {
print(i)
results = kappa2(cbind(conclusions_data_long[conclusions_data_long$coder == coderNames[1] & conclusions_data_long$Graph == i ,6], conclusions_data_long[conclusions_data_long$coder == coderNames[2] & conclusions_data_long$Graph == i,6]))
if(results[5]<1){
print(results)
}
}
#Now to combine both of these
conclusions_data_long = rbind(KA_data_long, EA_data_long)
#identify coder names
coderNames = unique(conclusions_data_long$coder)
# overall agreemeent with Cohen's Kappa
# 6 is hard coded as the column with the coding
results = kappa2(cbind(KA_data_long[6], EA_data_long[6]))
results
EA_data_long$coder = "EA"
require('dplyr')
require('irr')
library(tidyr)
KA_data_wide <- read.csv('IRR_declutter_redraw_KA.csv')
# this line takes out blank rows in csv if there are any
KA_data_wide <- KA_data_wide[!apply(KA_data_wide == "", 1, all),]
KA_data_long <- pivot_longer(KA_data_wide, s1:s34, names_to = "subject", values_to = "coding")
KA_data_long$coder = "KA"
# Adding EA's data
EA_data_wide <- read.csv('IRR_declutter_redraw_EA.csv')
# this line takes out blank rows in csv if there are any
EA_data_wide <- EA_data_wide[!apply(EA_data_wide == "", 1, all),]
#EA_data_long <- gather(EA_data_wide, key = "subject", value= "coding", s1:s34)
# gather was retired?
EA_data_long <- pivot_longer(EA_data_wide, s1:s34, names_to = "subject", values_to = "coding")
EA_data_long$coder = "EA"
#Now to combine both of these
redraw_data_long = rbind(KA_data_long, EA_data_long)
#identify coder names
coderNames = unique(redraw_data_long$coder)
# overall agreemeent with Cohen's Kappa
# 4 is hard coded as the column with the coding
# my apologies for the hard coding
results = kappa2(cbind(KA_data_long[4], EA_data_long[4]))
results
#Adding KA's data
KA_data_wide <- read.csv('IRR_declutter_conclusions_KA.csv')
KA_data_long <- gather(KA_data_wide, key = "subject", value= "coding", s1:s34)
KA_data_long$coder = "KA"
# Adding EA's data
EA_data_wide <- read.csv('IRR_declutter_conclusions_EA.csv')
EA_data_long <- gather(EA_data_wide, key = "subject", value= "coding", s1:s34)
EA_data_long$coder = "EA"
#Adding KA's data
KA_data_wide <- read.csv('IRR_declutter_conclusions_KA.csv')
KA_data_long <- gather(KA_data_wide, key = "subject", value= "coding", s1:s34)
KA_data_long$coder = "KA"
# Adding EA's data
EA_data_wide <- read.csv('IRR_declutter_conclusions_EA.csv')
EA_data_long <- gather(EA_data_wide, key = "subject", value= "coding", s1:s34)
EA_data_long$coder = "EA"
#Now to combine both of these
conclusions_data_long = rbind(KA_data_long, EA_data_long)
#identify coder names
coderNames = unique(conclusions_data_long$coder)
# overall agreemeent with Cohen's Kappa
# 6 is hard coded as the column with the coding
results = kappa2(cbind(KA_data_long[6], EA_data_long[6]))
results
#Adding EL's data
EL_data_wide <- read.csv('IRR_declutter_rating_EL.csv')
# this line takes out blank rows in csv if there are any
EL_data_wide <- EL_data_wide[!apply(EL_data_wide == "", 1, all),]
EL_data_long <- gather(EL_data_wide, key = "style", value= "coding", Cluttered:Focused)
EL_data_long$coder = "EL"
# Adding EA's data
EA_data_wide <- read.csv('IRR_declutter_rating_EA.csv')
# this line takes out blank rows in csv if there are any
EA_data_wide <- EA_data_wide[!apply(EA_data_wide == "", 1, all),]
EA_data_long <- gather(EA_data_wide, key = "style", value= "coding", Cluttered:Focused)
EA_data_long$coder = "EA"
#Now to combine both of these
rating_data_long = rbind(EL_data_long, EA_data_long)
#identify coder names
coderNames = unique(rating_data_long$coder)
# overall agreemeent with Cohen's Kappa
# 7 is hard coded as the column with the coding
results = kappa2(cbind(EL_data_long[7], EA_data_long[7]))
results
